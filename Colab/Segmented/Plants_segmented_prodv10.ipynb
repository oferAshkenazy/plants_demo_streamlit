{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvAA7cJ3-8po"
      },
      "outputs": [],
      "source": [
        "# ══ 1) Install / Upgrade Dependencies ════════════════════════════════════════\n",
        "!pip install --upgrade pip\n",
        "!pip install --quiet \\\n",
        "    opencv-python-headless \\\n",
        "    pandas \\\n",
        "    matplotlib \\\n",
        "    tqdm \\\n",
        "    scikit-learn \\\n",
        "    tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ══ 2) Mount Google Drive ══════════════════════════════════════════════════\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "4MSzMSMo_PKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ══ 3) Imports & Global Settings ═══════════════════════════════════════════\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import re\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Paths & Hyperparameters\n",
        "ROOT                 = '/content/drive/MyDrive/dataset/plantvillage dataset'\n",
        "COLOR_DIR            = os.path.join(ROOT, 'segmented')\n",
        "SAVE_DIR             = '/content/drive/MyDrive/saved_models_segmented_prodv10'\n",
        "IMG_SIZE             = (224, 224)\n",
        "BATCH_SIZE           = 32\n",
        "NUM_HEAD_EPOCHS      = 15\n",
        "NUM_FINE_TUNE_EPOCHS = 100\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "RLHf3isB_RSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ══ 3.1) Resume Helper & Callback Definition ════════════════════════════════\n",
        "class EpochCheckpoint(Callback):\n",
        "    \"\"\"Save model and history after each epoch with unique names.\"\"\"\n",
        "    def __init__(self, save_dir, base_name):\n",
        "        super().__init__()\n",
        "        self.save_dir = save_dir\n",
        "        self.base_name = base_name\n",
        "        self.history_per_epoch = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        ep = epoch + 1\n",
        "        mpath = os.path.join(self.save_dir, f\"{self.base_name}_{ep:02d}.h5\")\n",
        "        self.model.save(mpath)\n",
        "        self.history_per_epoch.append(logs.copy() if logs else {})\n",
        "        hpath = os.path.join(self.save_dir, f\"history_{self.base_name}_{ep:02d}.pkl\")\n",
        "        with open(hpath, 'wb') as f:\n",
        "            pickle.dump(self.history_per_epoch, f)\n",
        "\n",
        "\n",
        "def find_last_checkpoint(save_dir, base_name):\n",
        "    files = [f for f in os.listdir(save_dir) if re.match(f\"{base_name}_\\\\d+\\\\.h5\", f)]\n",
        "    if not files:\n",
        "        return None, None, 0\n",
        "    epochs = [int(re.findall(r\"(\\\\d+)\", f)[0]) for f in files]\n",
        "    last = max(epochs)\n",
        "    mpath = os.path.join(save_dir, f\"{base_name}_{last:02d}.h5\")\n",
        "    hpath = os.path.join(save_dir, f\"history_{base_name}_{last:02d}.pkl\")\n",
        "    return mpath, hpath, last\n"
      ],
      "metadata": {
        "id": "SlS-OePe_mb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ══ 4) Data Generators & Dataset Splits ═══════════════════════════════════════\n",
        "# 4.1) Build a DataFrame of all grayscale image paths + labels\n",
        "file_paths, labels = [], []\n",
        "for cls in os.listdir(COLOR_DIR):\n",
        "    class_dir = os.path.join(COLOR_DIR, cls)\n",
        "    for fname in os.listdir(class_dir):\n",
        "        file_paths.append(os.path.join(class_dir, fname))\n",
        "        labels.append(cls)\n",
        "df = pd.DataFrame({'filename': file_paths, 'class': labels})\n",
        "\n",
        "# 4.2) Stratified split: 80% train, 10% val, 10% test\n",
        "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['class'], random_state=42)\n",
        "val_df, test_df  = train_test_split(temp_df, test_size=0.5, stratify=temp_df['class'], random_state=42)\n",
        "\n",
        "# 4.3) Define data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1/255., rotation_range=20,\n",
        "    width_shift_range=0.1, height_shift_range=0.1,\n",
        "    shear_range=0.1, zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "test_val_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "# 4.4) Flow from DataFrame\n",
        "train_ds = train_datagen.flow_from_dataframe(\n",
        "    train_df, x_col='filename', y_col='class',\n",
        "    target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical', shuffle=True\n",
        ")\n",
        "val_ds = test_val_datagen.flow_from_dataframe(\n",
        "    val_df, x_col='filename', y_col='class',\n",
        "    target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical', shuffle=False\n",
        ")\n",
        "test_ds = test_val_datagen.flow_from_dataframe(\n",
        "    test_df, x_col='filename', y_col='class',\n",
        "    target_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical', shuffle=False\n",
        ")\n",
        "\n",
        "NUM_CLASSES = len(train_ds.class_indices)\n",
        "print(f\"Found {NUM_CLASSES} classes. Samples → train: {train_ds.n}, val: {val_ds.n}, test: {test_ds.n}\")"
      ],
      "metadata": {
        "id": "wC3CbDU__pop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Input, Model\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# ══ 5) Build Base Model ══════════════════════════════════════════════════════\n",
        "base_model = MobileNetV2(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(*IMG_SIZE, 3)\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = Input(shape=(*IMG_SIZE, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "uJNA-OVH_s80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ══ 6) Stage-1: Head Training (Resumeable) ══════════════════════════════════\n",
        "head_name = 'MobileNetV2_head'\n",
        "mp, hp, e0 = find_last_checkpoint(SAVE_DIR, head_name)\n",
        "if mp:\n",
        "    print(f\"Resuming head training from epoch {e0}\")\n",
        "    model.load_weights(mp)\n",
        "    initial_ep = e0\n",
        "else:\n",
        "    print(\"Starting head training from scratch\")\n",
        "    initial_ep = 0\n",
        "cb_head = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),\n",
        "    EpochCheckpoint(SAVE_DIR, head_name)\n",
        "]\n",
        "history1 = model.fit(\n",
        "    train_ds, validation_data=val_ds,\n",
        "    epochs=initial_ep + NUM_HEAD_EPOCHS,\n",
        "    initial_epoch=initial_ep,\n",
        "    callbacks=cb_head\n",
        ")\n",
        "print(f\"Head training complete. Latest checkpoint: {head_name}_{initial_ep+NUM_HEAD_EPOCHS:02d}.h5\")\n"
      ],
      "metadata": {
        "id": "6MTm0X8i_vwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ══ 8) Plot & Print Stage-1 Metrics & Test Evaluation ═════════════════════════════════════════\n",
        "def plot_history(hist, stage):\n",
        "    plt.figure()\n",
        "    plt.plot(hist.history['loss'],     label='train_loss')\n",
        "    plt.plot(hist.history['val_loss'], label='val_loss')\n",
        "    plt.title(f'{stage} Loss');    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.plot(hist.history['accuracy'],     label='train_acc')\n",
        "    plt.plot(hist.history['val_accuracy'], label='val_acc')\n",
        "    plt.title(f'{stage} Accuracy'); plt.legend()\n",
        "\n",
        "# 8.1) Head-only training curves\n",
        "plot_history(history1, 'Stage 1 (Head Only)')\n",
        "\n",
        "train_acc1 = history1.history['accuracy'][-1]\n",
        "val_acc1   = history1.history['val_accuracy'][-1]\n",
        "print(f\"Stage 1 final → Train Acc: {train_acc1:.4f}, Val Acc: {val_acc1:.4f}\")\n",
        "\n",
        "# 8.2) Evaluate head-only model on your held-out test set\n",
        "test_loss1, test_acc1 = model.evaluate(test_ds, verbose=1)\n",
        "print(f\"Stage 1 final → Test Loss: {test_loss1:.4f}, Test Acc: {test_acc1:.4f}\")\n",
        "\n",
        "# 8.3) Bar-chart comparison for Stage 1\n",
        "plt.figure()\n",
        "plt.bar(['train_acc','val_acc','test_acc'], [train_acc1, val_acc1, test_acc1])\n",
        "plt.title('Stage 1 Accuracy Comparison')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(\n",
        "    ['train_loss','val_loss','test_loss'],\n",
        "    [history1.history['loss'][-1], history1.history['val_loss'][-1], test_loss1]\n",
        ")\n",
        "plt.title('Stage 1 Loss Comparison')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MKDc34UU_yZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ══ 9) Stage-2: Fine-Tuning (Resumeable) ═══════════════════════════════════\n",
        "for layer in base_model.layers[-30:]:\n",
        "    layer.trainable = True\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "fine_name = 'rMobileNetV2_finetuned'\n",
        "mp2, hp2, e1 = find_last_checkpoint(SAVE_DIR, fine_name)\n",
        "if mp2:\n",
        "    print(f\"Resuming fine-tuning from epoch {e1}\")\n",
        "    model.load_weights(mp2)\n",
        "    initial_ft = e1\n",
        "else:\n",
        "    print(\"Starting fine-tuning from scratch\")\n",
        "    initial_ft = 0\n",
        "cb_ft = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7),\n",
        "    EpochCheckpoint(SAVE_DIR, fine_name)\n",
        "]\n",
        "history2 = model.fit(\n",
        "    train_ds, validation_data=val_ds,\n",
        "    epochs=initial_ft + NUM_FINE_TUNE_EPOCHS,\n",
        "    initial_epoch=initial_ft,\n",
        "    callbacks=cb_ft\n",
        ")\n",
        "print(f\"Fine-tuning complete. Latest checkpoint: {fine_name}_{initial_ft+NUM_FINE_TUNE_EPOCHS:02d}.h5\")\n"
      ],
      "metadata": {
        "id": "MbOBW_vT_06c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ══ 10) Plot & Print Stage-2 Metrics & Test Evaluation ══════════════════════════\n",
        "plot_history(history2, 'Stage 2 (Fine-Tune)')\n",
        "\n",
        "train_acc2 = history2.history['accuracy'][-1]\n",
        "val_acc2   = history2.history['val_accuracy'][-1]\n",
        "print(f\"Stage 2 final → Train Acc: {train_acc2:.4f}, Val Acc: {val_acc2:.4f}\")\n",
        "\n",
        "# 10.1) Evaluate on your held-out test set\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=1)\n",
        "print(f\"Stage 2 final → Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "# 10.2) Comparison bar-charts\n",
        "plt.figure()\n",
        "plt.bar(['train_acc','val_acc','test_acc'], [train_acc2, val_acc2, test_acc])\n",
        "plt.title('Stage 2 Accuracy Comparison')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(\n",
        "    ['train_loss','val_loss','test_loss'],\n",
        "    [history2.history['loss'][-1], history2.history['val_loss'][-1], test_loss]\n",
        ")\n",
        "plt.title('Stage 2 Loss Comparison')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "q8rjUMK__5jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(val_ds, verbose=1)\n",
        "print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "xwvU0TjZ_9cZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}